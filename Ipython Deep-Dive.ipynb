{
 "metadata": {
  "name": "",
  "signature": "sha256:32f1766540cdb5e2826985003e65e134dbdc2adf954a18a09c1ef3aa30e38ad0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import sklearn\n",
      "import sklearn.linear_model as lm\n",
      "import sklearn.cross_validation as cv\n",
      "import sklearn.grid_search as gs\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import train_test_split, Bootstrap\n",
      "from sklearn.datasets import make_blobs\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.dummy import DummyClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.linear_model import RandomizedLogisticRegression\n",
      "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.metrics import roc_auc_score\n",
      "from IPython.display import Image\n",
      "from sklearn.decomposition import PCA\n",
      "import sklearn.grid_search as gs\n",
      "from sklearn.metrics import recall_score\n",
      "conf_matrix_image = Image(url='https://computersciencesource.files.wordpress.com/2010/01/conmat.png')\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Overview"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The Goal of my project is optimizing video ads targeting based on historical user data. \n",
      "I am using a user categories data set from a recent Land Rover campaign, trying to build a predictive model that will predict\n",
      "the likelihood of visiting Land Rover Web Site\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "1. The Data Set "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data source comes from 3rd party data providers as well as Eyeview's data on User Activities "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pre - Processing Data\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The original data file cotained over 40K features. To make the data more managable I created a pre processing python script\n",
      "which merged some of the features and removed others, to make the data more managable. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load & Cleanup Data:\u00b6"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Each row represents one user. \n",
      "- The columns (or features) are the user categories - this is our \u201cX\u201d variable. <br>\n",
      "- The target (our \"Y\" variable) is the \"Visited Brand\" column, which is a true (\"1\") if the user either visited the \n",
      "  website in the past, or clicked on an ad - I assume that this means the user is \"Intrested In the Brand\"\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "u'/Users/asharon/MyDataScienceToolbox/ML_training'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Download file from (and adjust file path):\n",
      "# s3://eyeview-ari/DataScience/filtered_output_for_campaign_829.csv\n",
      "data = pd.read_csv('/Users/asharon/MyDataScienceToolbox/829/filtered_output_for_campaign_829.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = pd.read_csv('/vagrant/829/filtered_output_for_campaign_829.csv')\n",
      "\n",
      "df = data.fillna(0)  ## replace null values with zeros\n",
      "df = df.rename(columns={'PIA': 'Visited Brand'})\n",
      "df = df.drop(['DATE','USER ID', 'CAMPAIGN ID','Retargeting', 'Clicker'], axis=1) \n",
      "df = df.ix[:,(df != 0).any(axis=0)] ## remove all columns with all zeros\n",
      "df = df.ix[(df != 0).any(axis=1),:] ## remove all rows with all zeros\n",
      "X = df.drop(['Visited Brand'], axis=1)\n",
      "Y = df['Visited Brand']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Our data set contains 37645 rows and 1168 columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Exelate 10 - General Interest - Auto Enthusiasts</th>\n",
        "      <th>Exelate 1006 - General Interest - Green Living</th>\n",
        "      <th>Exelate 1007 - Politics - Political Junkies</th>\n",
        "      <th>Exelate 10082 - Finance and Insurance - Mortgages - Mortgage Hyper-Intent</th>\n",
        "      <th>Exelate 1017 - Shopping - Mobile - Carrier: AT&amp;T</th>\n",
        "      <th>Exelate 10179 - Travel - Departure - Europe</th>\n",
        "      <th>Exelate 1018 - Shopping - Mobile - Carrier: T-Mobile</th>\n",
        "      <th>Exelate 10180 - Travel - Departure - North America</th>\n",
        "      <th>Exelate 1019 - Shopping - Mobile - Carrier: Sprint</th>\n",
        "      <th>Exelate 1020 - Shopping - Mobile - Carrier: Verizon</th>\n",
        "      <th>...</th>\n",
        "      <th>Exelate 9315 - Auto - Buyers - Make:RAM - 1500</th>\n",
        "      <th>Exelate 9321 - Auto - Buyers - Make:Tesla - Model S</th>\n",
        "      <th>Exelate 9638 - Finance and Insurance - Auto Intenders</th>\n",
        "      <th>Exelate 9969 - Finance and Insurance - Banking - Checking and Savings</th>\n",
        "      <th>Exelate 9970 - Finance and Insurance - Credit Cards - Small Business</th>\n",
        "      <th>Exelate 9989 - CPG - Dish and Dishwasher Detergent</th>\n",
        "      <th>Exelate 3211 - Services - Personal Services and Care - Children Daycare</th>\n",
        "      <th>Exelate 5106 - Entertainment - Music - Jazz/Blues</th>\n",
        "      <th>Completer</th>\n",
        "      <th>Visited Brand</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>...</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1168 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "   Exelate 10 - General Interest - Auto Enthusiasts  \\\n",
        "0                                                 0   \n",
        "1                                                 1   \n",
        "2                                                 1   \n",
        "3                                                 1   \n",
        "4                                                 1   \n",
        "\n",
        "   Exelate 1006 - General Interest - Green Living  \\\n",
        "0                                               0   \n",
        "1                                               0   \n",
        "2                                               1   \n",
        "3                                               1   \n",
        "4                                               0   \n",
        "\n",
        "   Exelate 1007 - Politics - Political Junkies  \\\n",
        "0                                            0   \n",
        "1                                            0   \n",
        "2                                            1   \n",
        "3                                            1   \n",
        "4                                            0   \n",
        "\n",
        "   Exelate 10082 - Finance and Insurance - Mortgages - Mortgage Hyper-Intent  \\\n",
        "0                                                  0                           \n",
        "1                                                  0                           \n",
        "2                                                  0                           \n",
        "3                                                  0                           \n",
        "4                                                  0                           \n",
        "\n",
        "   Exelate 1017 - Shopping - Mobile - Carrier: AT&T  \\\n",
        "0                                                 0   \n",
        "1                                                 0   \n",
        "2                                                 0   \n",
        "3                                                 0   \n",
        "4                                                 0   \n",
        "\n",
        "   Exelate 10179 - Travel - Departure - Europe  \\\n",
        "0                                            0   \n",
        "1                                            0   \n",
        "2                                            0   \n",
        "3                                            0   \n",
        "4                                            0   \n",
        "\n",
        "   Exelate 1018 - Shopping - Mobile - Carrier: T-Mobile  \\\n",
        "0                                                  0      \n",
        "1                                                  0      \n",
        "2                                                  0      \n",
        "3                                                  0      \n",
        "4                                                  0      \n",
        "\n",
        "   Exelate 10180 - Travel - Departure - North America  \\\n",
        "0                                                  0    \n",
        "1                                                  0    \n",
        "2                                                  0    \n",
        "3                                                  0    \n",
        "4                                                  0    \n",
        "\n",
        "   Exelate 1019 - Shopping - Mobile - Carrier: Sprint  \\\n",
        "0                                                  0    \n",
        "1                                                  0    \n",
        "2                                                  0    \n",
        "3                                                  0    \n",
        "4                                                  0    \n",
        "\n",
        "   Exelate 1020 - Shopping - Mobile - Carrier: Verizon      ...        \\\n",
        "0                                                  0        ...         \n",
        "1                                                  0        ...         \n",
        "2                                                  0        ...         \n",
        "3                                                  0        ...         \n",
        "4                                                  0        ...         \n",
        "\n",
        "   Exelate 9315 - Auto - Buyers - Make:RAM - 1500  \\\n",
        "0                                               0   \n",
        "1                                               0   \n",
        "2                                               0   \n",
        "3                                               0   \n",
        "4                                               0   \n",
        "\n",
        "   Exelate 9321 - Auto - Buyers - Make:Tesla - Model S  \\\n",
        "0                                                  0     \n",
        "1                                                  0     \n",
        "2                                                  0     \n",
        "3                                                  0     \n",
        "4                                                  0     \n",
        "\n",
        "   Exelate 9638 - Finance and Insurance - Auto Intenders  \\\n",
        "0                                                  0       \n",
        "1                                                  0       \n",
        "2                                                  0       \n",
        "3                                                  1       \n",
        "4                                                  1       \n",
        "\n",
        "   Exelate 9969 - Finance and Insurance - Banking - Checking and Savings  \\\n",
        "0                                                  0                       \n",
        "1                                                  1                       \n",
        "2                                                  1                       \n",
        "3                                                  1                       \n",
        "4                                                  1                       \n",
        "\n",
        "   Exelate 9970 - Finance and Insurance - Credit Cards - Small Business  \\\n",
        "0                                                  0                      \n",
        "1                                                  1                      \n",
        "2                                                  1                      \n",
        "3                                                  1                      \n",
        "4                                                  1                      \n",
        "\n",
        "   Exelate 9989 - CPG - Dish and Dishwasher Detergent  \\\n",
        "0                                                  0    \n",
        "1                                                  0    \n",
        "2                                                  0    \n",
        "3                                                  1    \n",
        "4                                                  0    \n",
        "\n",
        "   Exelate 3211 - Services - Personal Services and Care - Children Daycare  \\\n",
        "0                                                  0                         \n",
        "1                                                  0                         \n",
        "2                                                  0                         \n",
        "3                                                  0                         \n",
        "4                                                  0                         \n",
        "\n",
        "   Exelate 5106 - Entertainment - Music - Jazz/Blues  Completer  Visited Brand  \n",
        "0                                                  0          1              0  \n",
        "1                                                  0          0              0  \n",
        "2                                                  0          1              1  \n",
        "3                                                  0          1              0  \n",
        "4                                                  0          1              1  \n",
        "\n",
        "[5 rows x 1168 columns]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Visualize"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets do some simple visualization of our data, just to get a \"feel\".\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_df_row = df.sum(axis=1) ## sum of each row\n",
      "plt.hist(sum_df_row,20)\n",
      "plt.xlabel('Number of features per user bucket')\n",
      "plt.ylabel('Users Count in bucket')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<matplotlib.text.Text at 0x10c5190d0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEPCAYAAACOU4kjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nObmYmVnhnFzMzKxw/x8q4Kjzudf50AAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10c9d1dd0>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above histogram shows the ditrubution of Number of features and user count. as expected, most users have a low number of\n",
      "features, between 0-25"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Lets see which categories are the most common in our data set: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_df_col = df.sum(axis=0) ## sum of each column\n",
      "sum_df_col.sort(ascending=False)\n",
      "sum_df_col.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "Completer                                                    26877\n",
        "Exelate 25 - Entertainment                                   25182\n",
        "Exelate 2 - Finance                                          20855\n",
        "Exelate 40 - Shopping                                        19625\n",
        "Exelate 3365 - General Interest - News and Current Events    17504\n",
        "Exelate 1141 - Services - Finance and Insurance - Banking    17403\n",
        "Exelate 9160 - Finance and Insurance                         17245\n",
        "Exelate 6229 - Auto Owners                                   17227\n",
        "Exelate 1438 - CPG                                           16730\n",
        "Exelate 32 - Hobbies                                         16719\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "2. Model Testing Process"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll start with one model to understand the basic workflow: <br>\n",
      "* Create <b>test - train</b> split: 80% of the data is used for fitting our model, 20% for testing the model.\n",
      "* Fit the model on training data (X_train, Y_train)\n",
      "* Predict probabilities of Test data (X_test) \n",
      "* Score the mofel performance by comparing predicted probabilities with actual resluts (Y_test) "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.1 Create test - train split"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(X_train, X_test,\n",
      " Y_train, Y_test) = cv.train_test_split(X, Y,\n",
      "                                            test_size=.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.2 Fit model - Logistic Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = LogisticRegression()\n",
      "model.fit(X_train,Y_train) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr = model.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Coefficients"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_df = pd.DataFrame(arr.reshape(1167,1), columns=['coef'])\n",
      "c_df['column'] = X.columns\n",
      "c_df = c_df.sort(columns='coef',ascending=False)\n",
      "c_df[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>coef</th>\n",
        "      <th>column</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>30 </th>\n",
        "      <td> 1.326378</td>\n",
        "      <td> Exelate 1135 - Services - Religious Organizations</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>52 </th>\n",
        "      <td> 1.194960</td>\n",
        "      <td> Exelate 11538 - Travel - Departure - North Ame...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>58 </th>\n",
        "      <td> 1.187096</td>\n",
        "      <td> Exelate 11544 - Travel - Departure - North Ame...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>488</th>\n",
        "      <td> 1.078829</td>\n",
        "      <td> Exelate 2819 - Travel - Destination - North Am...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>823</th>\n",
        "      <td> 1.066772</td>\n",
        "      <td> Exelate 538 - Travel - Destination - Asia - Ho...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "         coef                                             column\n",
        "30   1.326378  Exelate 1135 - Services - Religious Organizations\n",
        "52   1.194960  Exelate 11538 - Travel - Departure - North Ame...\n",
        "58   1.187096  Exelate 11544 - Travel - Departure - North Ame...\n",
        "488  1.078829  Exelate 2819 - Travel - Destination - North Am...\n",
        "823  1.066772  Exelate 538 - Travel - Destination - Asia - Ho..."
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.3 Visualization - Display first 10 rows of test set, their predicted probabiliy and actual values "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_test_predicted_prob = model.predict_proba(X_test)\n",
      "pd.DataFrame({'Prob of 1' : pd.Series(Y_test_predicted_prob[:10,1]), 'Actaul value' : Y_test[:10]  })"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Actaul value</th>\n",
        "      <th>Prob of 1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0.332386</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0.139763</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0.169226</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0.285114</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0.165763</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0.175205</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0.188574</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0.178541</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0.556371</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0.150362</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "   Actaul value  Prob of 1\n",
        "0             0   0.332386\n",
        "1             0   0.139763\n",
        "2             0   0.169226\n",
        "3             0   0.285114\n",
        "4             0   0.165763\n",
        "5             0   0.175205\n",
        "6             1   0.188574\n",
        "7             0   0.178541\n",
        "8             1   0.556371\n",
        "9             0   0.150362"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "printPredictionPlot(Y_test_predicted_prob, Y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'printPredictionPlot' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-34-aae3d77665d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprintPredictionPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_predicted_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'printPredictionPlot' is not defined"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2.4 Scoring Method"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.4.1 Confusion Matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def printConfusionMatrix(model, threshold, X_train, X_test, Y_train, Y_test):\n",
      "    \n",
      "    model.fit(X_train,Y_train) \n",
      "    y_pred = predictWithThreshhold(model, threshold, X_test)\n",
      "    \n",
      "    c_m =  metrics.confusion_matrix(Y_test, y_pred) \n",
      "    print c_m\n",
      "    \n",
      "    \n",
      "def predictWithThreshhold(model, threshhold, x_test):\n",
      "    \n",
      "    prob = model.predict_proba(x_test)\n",
      "    return map(lambda x: 1 if x[1] > threshhold else 0, prob)\n",
      "\n",
      "\n",
      "printConfusionMatrix(LogisticRegression(), 0.5, X_train, X_test, Y_train, Y_test)\n",
      "print 'accuracy score: ',model.score(X_test,Y_test) #Returns the mean accuracy\n",
      "conf_matrix_image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[4868  474]\n",
        " [1600  587]]\n",
        "accuracy score:  0.724531810333\n"
       ]
      },
      {
       "html": [
        "<img src=\"https://computersciencesource.files.wordpress.com/2010/01/conmat.png\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "<IPython.core.display.Image at 0x10c8e5790>"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.4.2 - Roc_Auc"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Roc_auc is the best scoring method for our problem as it takes into accout all the different possible thresholds.<br> In addition, roc_auc works for highly unbalanced classes. <br> Choosing the actual threshold is more of a business decision - do I want to maximize TP Rate or minimize FP rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prob_array = np.array(Y_test_predicted_prob)\n",
      "y_predicted_prob = prob_array[:,1]\n",
      "score_roc_auc = roc_auc_score(Y_test, y_predicted_prob)   \n",
      "print \"Roc Score: \", score_roc_auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Roc Score:  0.702166599439\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display_roc_curve(Y_test, Y_test_predicted_prob)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "3. Model selection - find best model"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Model Tester automates the model testing process and allows us to easily test different models.(See implementaion in the end of this notebook)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "classifiers = {'Logistic': LogisticRegression(),\n",
      "               'BernoulliNB': BernoulliNB(),                                     \n",
      "               'RandomForest': RandomForestClassifier(),\n",
      "               'AdaBoostClassifier' : AdaBoostClassifier()\n",
      "               }\n",
      "\n",
      "modelTester = ModelTester(X,Y,classifiers)\n",
      "## test_classifiers recieves the number of times to run each model (each time\n",
      "## on different training set). In this case - 3 times\n",
      "modelTester.test_classifiers(3) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "testing model:  RandomForest\n",
        "RandomForest had an average roc_auc score of 0.649 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "testing model:  BernoulliNB\n",
        "BernoulliNB had an average roc_auc score of 0.631 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "testing model:  AdaBoostClassifier\n",
        "AdaBoostClassifier had an average roc_auc score of 0.708 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "testing model:  Logistic\n",
        "Logistic had an average roc_auc score of 0.697 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ModelTester:\n",
      "    def __init__(self, X, Y,classifiers):\n",
      "        self.X_matrix = X\n",
      "        self.Y_vector = Y        \n",
      "        self.classifiers = classifiers\n",
      "        self.printConfusionMatrix = False\n",
      "        self.verbose = False\n",
      "        \n",
      "        \n",
      "        \n",
      "    def runClassifier(self, X,Y, clf, times): \n",
      "        sum_scores = 0.0\n",
      "        sum_scores_roc_auc = 0.0\n",
      "        conf_matrix = None\n",
      "        conf_matrix = np.array([[0,0], [0,0]])\n",
      "        printCurve = False\n",
      "\n",
      "        for i in range(times):\n",
      "             (X_train, X_test,\n",
      "             y_train, y_test) = cv.train_test_split(X, Y,\n",
      "                                                test_size=.2)\n",
      "             clf.fit(X_train,y_train)\n",
      "             self.clf_ = clf   \n",
      "             prob_array = np.array(clf.predict_proba(X_test))\n",
      "             y_hat = prob_array[:,1]\n",
      "             y_pred = clf.predict(X_test)\n",
      "             roc_score = roc_auc_score(y_test, y_hat)  \n",
      "             if self.verbose:   \n",
      "                 print \"current roc score: \", roc_score  \n",
      "             if printCurve:                        \n",
      "                 display_roc_curve(y_test,prob_array)\n",
      "                 printCurve = False       \n",
      "             sum_scores_roc_auc += roc_score      \n",
      "             sum_scores += recall_score(y_test, y_pred)\n",
      "             if (self.printConfusionMatrix):                 \n",
      "                conf_matrix += metrics.confusion_matrix(y_test, y_pred)       \n",
      "\n",
      "             #print \"%s had an accuracy score of %0.2f\"% (name, score)            \n",
      "        return sum_scores / times, sum_scores_roc_auc / times, conf_matrix / times\n",
      "\n",
      "    def test_classifiers(self, times):\n",
      "        for name, clf in self.classifiers.items():\n",
      "            print \"testing model: \", name\n",
      "            score, score_roc_auc, conf_matrix = self.runClassifier(self.X_matrix,self.Y_vector,clf, times)   \n",
      "            #print \"%s had an average recall score of %0.3f, and roc_auc score of %0.2f\"% (name, score, score_roc_auc)\n",
      "            print \"%s had an average roc_auc score of %0.3f \\n\"% (name, score_roc_auc)\n",
      "            if (self.printConfusionMatrix):\n",
      "                print \"confusion matrix: \"\n",
      "                print conf_matrix\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "4. Optimize models with grid search "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Grid search allows us to easily test different parameters for each model. ModelOptimizer is a class that automates gridSearch on multiple models (see implementation in the end of this notebook)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modelOptimizer= ModelOptimizer(X, Y)\n",
      "modelOptimizer.add_model(\"BernoulliNB\",BernoulliNB(),param_grid={'alpha':np.linspace(0.01, .2, 5)} )\n",
      "modelOptimizer.add_model(\"Logistic\",LogisticRegression(),param_grid={'C':np.linspace(0.0001, 0.2, 10)})\n",
      "modelOptimizer.add_model(\"RandomForest\",RandomForestClassifier(),param_grid={'max_depth':range(5,9,1),'n_estimators':[90,200,300], 'max_features' : ['sqrt', 'log2'] } )\n",
      "modelOptimizer.add_model(\"AdaBoostClassifier\",AdaBoostClassifier(),param_grid={'n_estimators':[90,200,300] })\n",
      "modelOptimizer.test_models()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB: \n",
        "------------------------\n",
        "score: 0.624579355793\n",
        "best estomator:  BernoulliNB(alpha=0.15250000000000002, binarize=0.0, class_prior=None,\n",
        "      fit_prior=True)\n",
        "best params:  {'alpha': 0.15250000000000002}\n",
        "\n",
        "Logistic: \n",
        "------------------------\n",
        "score: 0.703818914304\n",
        "best estomator:  LogisticRegression(C=0.022311111111111111, class_weight=None, dual=False,\n",
        "          fit_intercept=True, intercept_scaling=1, penalty='l2',\n",
        "          random_state=None, tol=0.0001)\n",
        "best params:  {'C': 0.022311111111111111}\n",
        "\n",
        "RandomForest: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "------------------------\n",
        "score: 0.700338800137\n",
        "best estomator:  RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=8, max_features='sqrt',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=300, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)\n",
        "best params:  {'max_features': 'sqrt', 'n_estimators': 300, 'max_depth': 8}\n",
        "\n",
        "AdaBoostClassifier: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "------------------------\n",
        "score: 0.701937078252\n",
        "best estomator:  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
        "          learning_rate=1.0, n_estimators=90, random_state=None)\n",
        "best params:  {'n_estimators': 90}\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The best models are: RandomForest, LogisticRegression and AdaBoost"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "5. Additional Optimization attempts"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.1 Remove features with less than 10000 users"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_filtered = df.ix[:,df.sum(axis=0) > 10000]\n",
      "X_filtered = df_filtered.drop(['Visited Brand'], axis=1)\n",
      "Y_filtered = df['Visited Brand']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_filtered.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "(37645, 50)"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modelTester = ModelTester(X_filtered,Y_filtered,{'Logistic': LogisticRegression()})\n",
      "modelTester.test_classifiers(3) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "testing model:  Logistic\n",
        "Logistic had an average roc_auc score of 0.699 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr = modelTester.clf_.coef_\n",
      "arr.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "(1, 50)"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_df = pd.DataFrame(arr.reshape(50,1), columns=['coef'])\n",
      "c_df['column'] = X_filtered.columns\n",
      "c_df = c_df.sort(columns='coef',ascending=False)\n",
      "#c_df\n",
      "#tmp = df[['Exelate 222 - Auto - Buyers - Make:BMW', 'Visited Brand']]\n",
      "#tmp[tmp['Exelate 222 - Auto - Buyers - Make:BMW'] == 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modelOptimizer= ModelOptimizer(X_filtered, Y_filtered)\n",
      "modelOptimizer.add_model(\"BernoulliNB\",BernoulliNB(),param_grid={'alpha':np.linspace(0.01, .2, 5)} )\n",
      "modelOptimizer.add_model(\"Logistic\",LogisticRegression(),param_grid={'C':np.linspace(0.0001, 0.2, 10)})\n",
      "modelOptimizer.add_model(\"RandomForest\",RandomForestClassifier(),param_grid={'max_depth':range(5,9,1),'n_estimators':[90,200,300], 'max_features' : ['sqrt', 'log2'] } )\n",
      "modelOptimizer.add_model(\"AdaBoostClassifier\",AdaBoostClassifier(),param_grid={'n_estimators':[90,200,300] })\n",
      "modelOptimizer.test_models()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tmp = df[['Exelate 222 - Auto - Buyers - Make:BMW', 'Visited Brand']]\n",
      "#tmp[tmp['Exelate 222 - Auto - Buyers - Make:BMW'] == 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testDataFrame(df_filtered)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(37645, 811)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB: \n",
        "------------------------\n",
        "score: 0.62370416378\n",
        "best estomator:  BernoulliNB(alpha=0.03111111111111111, binarize=0.0, class_prior=None,\n",
        "      fit_prior=True)\n",
        "best params:  {'alpha': 0.03111111111111111}\n",
        "\n",
        "Logistic: \n",
        "------------------------\n",
        "score: 0.702768092924\n",
        "best estomator:  LogisticRegression(C=0.10000000000000001, class_weight=None, dual=False,\n",
        "          fit_intercept=True, intercept_scaling=1, penalty='l2',\n",
        "          random_state=None, tol=0.0001)\n",
        "best params:  {'C': 0.10000000000000001}\n",
        "\n",
        "RandomForest: \n",
        "------------------------\n",
        "score: 0.697006533111\n",
        "best estomator:  RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=6, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)\n",
        "best params:  {'max_depth': 6}\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 221
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.2 Dimension Reduction with Principal component analysis (PCA)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import PCA\n",
      "from sklearn.decomposition import SparsePCA\n",
      "sk_pca = PCA(n_components=200)\n",
      "sk_transf = sk_pca.fit_transform(X)\n",
      "explained_variance = [sk_pca.explained_variance_ratio_[0:i].sum() for i in range(200)]\n",
      "plot(range(200),explained_variance)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7fc4137ae950>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGo5JREFUeJzt3XmclNWd7/EPsjhRwSUaUAFRxAiuqEEEiaViAo4Rlxhc\n7iSjM5GXRieL84qDo3faZDIT701uNCHXkMjVuA1qjMtNRMRgmXED3DCyXRCIgC0uGEdFBOy6f/yq\n7eqmuqu6qXpq6c/79XpetTxPP3V4LL99+pzznAOSJEmSJEmSJEmSJEmSJEnd1gRgKbAcuDLP/t2B\n+4CFwDzgkOSKJknqqp7ACmAI0Bt4ERje5pj/CVyTff5Z4NGkCidJat8OBfaPIgJ+NbAFmAlManPM\ncOCx7PNlxC+DvUpWQklSlxQK+H2BNTmv12bfy7UQOCv7fBSwHzCwJKWTJHVZoYDPFHGOHwK7AS8A\nl2UfP97OckmStlOvAvvXAYNyXg8iavG53gMuynm9CljZ9kRDhw7NvPLKK10poyR1Z68AB3blB3sU\n2N+LaFc/GXgNmA+cByzJOWZX4ENgM/B1YCzwt3nOlclkivmDQMVoaGigoaGh0sWoC17L0uqO1zOT\ngbfegj//uWV79dXWrz/8EAYPjm3QIBg4MB6bt4EDoV+/bc/do0cPKJzVeRWqwW8lml1mEyNqZhDh\nPiW7fzowAriFaM55Gfi7rhREkqrV1q2wbt22oZ0b5p/6VIT3fvu1bOPGtby3117Qo0sx3XWFAh5g\nVnbLNT3n+dPE8EhJqkmZDKxfD6tWwcqVrbfVq6GxET7zmZbgHjwYRo6EM85oed23b6X/FdsqJuBV\nhVKpVKWLUDe8lqVVrddz48aWAG8b5KtWwU47wQEHtGxjx8Lf/A0MGRLNJ336VPpf0HlJ/sFgG7yk\nsslk4I03YPlyWLGidXivXAnvvBNhnRviBxwA++8fW77272qwPW3wBrykmtHcmbl8eUuQNz9fvhx6\n94Zhw+DAA2Ho0NZBvvfesEOhgeFVyICXVDcyGdiwoXVw54Z5jx4R4rnbgQfG4x57VLr0pWfAS6o5\nmzdHaC9dCkuWxOOyZRHimcy24d287bFH8qNRKsmAl1S13nknwjt3W7Ikhhbutx8cfHBsw4fDQQdF\niO+5Z/cK8Y4Y8JIqqqkJ1qxpHeDNzzdubAnx3DAfOrQ2R6YkzYCXlIhMBtauhUWLWraXX45A79cv\ngnv48NZhvs8+1sa3hwEvqaQymbi5pznAm8N88eIYL37IIbEdemg8jhgBu+1W6VLXJwNeUpe99Ra8\n9FLrIF+0KIYc5oZ481aPI1WqmQEvqaAtW2KUyksvwcKFLY8bN8Jhh8WWG+R7uWxPVTDgJbXy5pvb\nBvmyZTFr4RFHwOGHtzwOHmwbeTUz4KVuauvWCO4XX2wd6Bs3bhvkhx4a7eeqLQa81A1s2RJt488/\nH9tzz8Gf/hS34I8c2TrQBw2yVl4vDHipzmzaFJ2ezUH+/PMR7kOGwNFHw1FHxTZyZPVOkqXSMOCl\nGvbRR9HE8txzLWG+bFnc0dkc5EcfHbXzXXapdGmVtHIH/ATgemJFp5uA69rs3xO4HRhAzC//I2KF\np7YMeHV7TU0x18r8+TBvXjwuWhRh/rnPtYT5YYfFCkFSOQO+J7Em63hiAe4FbLsmawOwIzCVCPtl\nQH9iub9cBry6nTfeaAnyefNgwQLYdVc49lgYNSoejzrKzk+1r5xrso4CVgCrs69nApNoHfCNwOHZ\n5/2At9k23KW6t3FjNK80h/m8efDuu1EzP/ZYuPzyCPX+/StdUnUXhQJ+X2BNzuu1wLFtjvkVMBd4\nDegLfKVkpZOq2GuvwVNPwZNPxrZoUdwgNGoUnHYafO970fRSi4tMqD4UCvhi2lSuAl4EUsBQYA5w\nBPBe2wMbGho+eZ5Kpap27UaprY8/jlEtuYH+X/8FY8bE2p0//jEcc4zt5tp+6XSadDpdknMVatcZ\nTbSxT8i+ngo00bqj9SHgB8CT2dd/AK4Enm1zLtvgVTPeey+aWprD/JlnYMCACPOxYyPYP/tZa+cq\nv3J2svYiOk1PJppg5rNtJ+v/At4FriU6V58j2uQ3tDmXAa+q9eab8Mc/wuOPwxNPxDDFkSNbAv24\n45ybRZVR7mGSE2kZJjkD+HdgSnbfdGLkzM3AYGCH7P4785zHgFfVWL8+wrx5W7s2gvyEE2DcuBjZ\nsuOOlS6l5I1OUkGNjS1hnk7D66/D8cdDKhWhfuSR0KtQj5RUAQa81Ma6dS1h/vjj0QTz+c9HmJ9w\nQszX0rNnpUspFWbAq9t75x147DGYMwcefRQ2bGgJ81Qq7gy1Q1S1yIBXt/PRR/D00xHmc+bEUnJj\nx8Ipp8D48Qa66ocBr7qXycQ49OYa+hNPxILO48dHqI8ZY6eo6pMBr7rU2AiPPNIS6jvv3BLoJ53k\n2qDqHgx41YWtW+OGolmzYlu1Ck4+OQL9lFPggAMqXUIpeQa8atb69fDww/DQQ1FTHzwYTj0VJk6E\n0aOhd+9Kl1CqLANeNePjj2OWxVmzItRXroxa+qmnwoQJsM8+lS6hVF0MeFW1DRsizH//+2hTHzgw\nauinnhpTAFhLl9pnwKvqrF4NDzwQ27PPRqfoaadFLX3gwEqXTqodBrwqLpOJxS6aQ72xEb70JZg0\nKUa+uGKR1DUGvCpi8+aYCuCBB+DBB2Mu9EmTYjvuOKcCkEqhnEv2Sa1s2gSzZ8M990Sb+sEHR6A/\n8kg875FklUFSh6zBq6BNm2Io4z33RGfpkUfCOefAmWfC3ntXunRSfbOJRiWXG+q//30sfnHOOXDW\nWbGykaRkGPAqiQ8/jOaXu++OmvpRR7WEev/+lS6d1D2VO+An0LKi0020Xo8V4B+BC7LPewHDiVWe\n/tLmOAO+Cm3dCnPnwh13REdpbk3dUJcqr5wB35NYk3U8sA5YwLZrsuY6DfhW9vi2DPgqkcnAc89F\nqM+cCYMGwQUXwOTJNr9I1aaco2hGASuA1dnXM4FJtB/w5wP/0ZWCqPxWroxQv+OOqLlfcEGsdnTQ\nQZUumaRyKBTw+wJrcl6vBY5t59idgC8Cl5agXCqRDRuiln777bBiRdTSb7kFjj3WIY1SvSsU8J1p\nU/kS8ATbtr1/oqGh4ZPnqVSKVCrVidOrWB9/HDMz3nxzdJpOnAhXXx1T7jrvi1Td0uk06XS6JOcq\nVIcbDTQQHa0AU4Emtu1oBbgPuItoxsnHNvgyW7EiQv3Xv47x6RddBOeeC7vvXumSSeqqcnay9iI6\nWU8GXgPmk7+TdVdgJTAQ+LCdcxnwZfDBBzFW/eabYenSaFe/8MJYk1RS7StnJ+tW4DJgNjGiZgYR\n7lOy+6dnH8/IHtNeuKvEFi+GG2+MDtMxY+Bb34K//mvo06fSJZNULbzRqYZs3gz33RfBvmwZ/P3f\nw9e/HqsgSapPTjZW5159FX75S5gxIyb0+sY34Iwz7DCV1LEdKl0A5dfUFHPBTJoUd5e+917ccfrY\nY3GnqeEuqRBr8FXm/fdjFMz110O/fnDppXDnnbDzzpUumaRaY8BXiTVrYNq0aIY54YS4GWnMGG9G\nktR1NtFU2IIFcN55cMQR0Ym6YAHcey+MHWu4S9o+BnwFZDLwhz/EQtRf/jIccwysWgU/+Qnsv3+l\nSyepXthEk6BMJhbP+MEPYo6Yq66C88+3w1RSeRjwCWhqgt/+NoK9qQn++Z/h7LNdlFpSeRnwZdTU\nBL/5DTQ0xIiY730PTjvNtnVJyTDgyyCTgd/9Dq65JqYO+MlP4AtfMNglJcuAL6HmztOrr4aNG+H7\n34fTTzfYJVWGAV8iTz0VnaaNjXDttfCVr8AOjlGSVEFG0HZ65ZUY6njuufDVr8KiRfHccJdUacZQ\nF23YAN/5DowaFXPFLF0aC2z08m8iSVXCgO+kzZtjnpiDD4529sWLY9jjTjtVumSS1Jr1zU743e/g\n29+GYcNiVsdDDql0iSSpfcXU4CcAS4HlwJXtHJMCXgBeBtKlKFg1+fOfY9reK66An/8cHnrIcJdU\n/QoFfE9gGhHyI4j1WIe3OWY34OfAl4BDgS+XuIwVs3kz/PCHcPTR0db+0ksxnl2SakGhJppRwApg\ndfb1TGASrRfdPh+4F1ibff1WCctXMY89FnOxH3AAzJ8fj5JUSwoF/L7AmpzXa4Fj2xwzDOgNPAb0\nBW4AbitVAZP21lvRzv7HP8INN0TTjDcqSapFhQK+mFWyewNHAScDOwFPA88QbfatNDQ0fPI8lUqR\nSqWKLGYyHngALrkkxrEvXuwqSpKSl06nSafTJTlXobrpaKCBaIMHmAo0AdflHHMl8KnscQA3AQ8D\nv2lzrkwmU8zvi+S98w5885txN+ott8Dxx1e6RJIUekQTQpfaEQp1sj5LNMEMAfoAk4EH2xzzAHA8\n0SG7E9GEs7grhamEhx6Cww6DXXeFhQsNd0n1o1ATzVbgMmA2EeAziA7WKdn904khlA8DLxG1+19R\nAwH/7rtxJ+rcuXDbbXDiiZUukSSVVpLdh1XTRPPii3DWWXDKKfCjH0HfvpUukSTltz1NNN3uTta7\n7oLLLoOf/Sw6UyWpXnWbgG9qipWVbr0VHn0Ujjii0iWSpPLqFgH/wQfwta/FXO3z5kH//pUukSSV\nX93PJrlmDYwbF2Pa58413CV1H3Ud8AsWwOjR0dZ+yy2w446VLpEkJadum2jmzoXJk+FXv4Izzqh0\naSQpeXUZ8PffDxdfDPfcA1U2G4IkJabummhuvTXmk5k1y3CX1L3V1Y1OzZOFzZ0bS+pJUq3bnhud\n6ibgn3wSzjwz5pY55piyfYwkJaqck43VhMWLY+qB224z3CWpWc0H/Ouvw8SJMafMF79Y6dJIUvWo\n6SaazZvhpJNg/PiYhkCS6k23bYO/5BJ47TW47z7Yoeb/FpGkbXXL2SRvuikWxp4/33CXpHyKicYJ\nxKIey4nl+dpKAe8CL2S3q0tVuPbMnw9XXRU3NPXrV+5Pk6TaVKgG3xOYBowH1gELiCX7lrQ57nHg\n9JKXLo9Nm2JmyGnTHOsuSR0pVIMfBawAVgNbgJnApDzHJdaW/2//FsF+zjlJfaIk1aZCNfh9gTU5\nr9cSi2rnygBjgIVELf8fKdOarIsWwY03xuLYPZLsHpakGlQo4IsZ9vI8MAjYCEwE7gcO2s5ybVuQ\nDFx6KVx7LeyzT6nPLkn1p1DAryPCu9kgohaf672c57OA/w3sAWxoe7KGnMHqqVSKVCdmA7vjjliZ\nacqUon9EkmpOOp0mnU6X5FyFGjp6AcuAk4HXgPnAebTuZO0PvEHU9kcBdwND8pyry+Pg//IXGDEi\nRs2MGtWlU0hSTSrnOPitwGXAbGJEzQwi3Jvr0dOBLwOXZI/dCJzblYJ05Jpr4PTTDXdJ6oyqv5P1\n+efh1FNjQrE99ihDqSSpitXtbJKZDFxxBXz/+4a7JHVWVQf8nDnQ2AgXXljpkkhS7anagG9qgqlT\n4V//FXrV7Iw5klQ5VRvws2ZFyJ99dqVLIkm1qWoD/oYb4Nvf9o5VSeqqqhxFs3gxnHwyrF4NO+5Y\n3kJJUjWru1E0P/1p3LFquEtS11VdDf7dd2HIEFiyBAYMKH+hJKma1VUN/vbb4ZRTDHdJ2l5VFfCZ\nDEyf7oRiklQKVRXwzzwTKzadeGKlSyJJta+qAv4Xv4CLL3YRbUkqharpZH3nHTjgAFi+HPbcM8FS\nSVIVq4tO1ltvjVkjDXdJKo2qCPhMJppn7FyVpNKpioB/+ukI+XHjKl0SSaofxQT8BGApsBy4soPj\nPkes6nRWZwtx991w/vnOOyNJpVQoUnsSa7KOJxbgXsC2a7I2HzeHWLLvZuDePOfK28na1ASDBsGj\nj8Lw4Z0rvCTVu3J2so4CVgCrgS3ATGBSnuMuB34DvNnZAjz5JHz604a7JJVaoYDfF1iT83pt9r22\nx0wCbsy+7tTCq3ffDZMnd+YnJEnFKLRWUjFhfT3wT9lje9DJPyUeeABmz+7MT0iSilEo4NcBg3Je\nDyJq8bmOJppuAPYEJhLNOQ+2PVlDQ8Mnz1OpFEOHpti0CQ4+uHOFlqR6lU6nSafTJTlXodp2L6KT\n9WTgNWA++TtZm90M/F/gt3n2bdPJetddMHMm3HdfZ4osSd3H9nSyFqrBbwUuA2YTI2VmEOHefEvS\n9K58aLMnn4QxY7bnDJKk9lR0Lppjjom1V8eOTbAUklRDtqcGX7GA/+AD+Mxn4O234a/+KsFSSFIN\nqcnJxhYsgMMPN9wlqVwqFvBPPQXHHVepT5ek+lexgH/5ZTjyyEp9uiTVv4oF/JIlTk8gSeVUkU7W\npibo2xcaG6FfvwRLIEk1puY6WV99FXbf3XCXpHKqSMAvXer0BJJUbhUJeNvfJan8rMFLUp2yBi9J\ndcoavCTVqcQD/u234aOPYO+9k/5kSepeEg/4FStg2DDokeQIfEnqhhIP+MZG2GefpD9VkrqfxAN+\n/XoYMCDpT5Wk7qeYgJ8ALAWWA1fm2T8JWAi8ADwHnNTRyV5/Hfr372QpJUmdVijgewLTiJAfQazH\n2naA46PAEcBI4G+BX3Z0QmvwkpSMQgE/ClgBrAa2ADOJGnuuD3Ke7wK81dEJX3/dgJekJBQK+H2B\nNTmv12bfa+sMYjHuWcA/dHRCm2gkKRm9CuzPFNjf7P7sNg64DfhsvoMaGhpYsgTuvhu2bk2RSqWK\nLqgkdQfpdJp0Ol2ScxUajT4aaCDa4AGmAk3AdR38zCtE087bbd7PZDIZdt45avF9+3ahtJLUzZRz\nPvhngWHAEKAPMBl4sM0xQ3M+/KjsY9twB+D99+Nxl106XU5JUicVaqLZClwGzCZG1Mwg2tqnZPdP\nB84Gvkp0wr4PnNveyZrb372LVZLKL9El+/7zPzN897vw1FMJfqok1bCaWbLPMfCSlJxEA94hkpKU\nnMQD3hq8JCUj8SYaa/CSlAxr8JJUp+xklaQ6lWjAv/EG7LVXkp8oSd1XogH/4Yew005JfqIkdV+J\nBvxHH0GfPkl+oiR1X4kG/ObNsOOOSX6iJHVfidfgDXhJSkaiAd/UBL0KTW8mSSqJRAO+Tx9nkpSk\npCQa8DbPSFJyDHhJqlMGvCTVqWIDfgKwFFgOXJln/wXAQuAl4Eng8HwnMeAlKTnFjGnpCUwDxgPr\ngAXEuqxLco5ZCXweeJf4ZfBLYsHuVrzJSZKSU0wNfhSwAlhNrLs6E5jU5piniXAHmAcMzHcia/CS\nlJxiAn5fYE3O67XZ99rzd8BD+XYY8JKUnGKaaDKdON+JwEXA2Hw7GxsbaGiI56lUilQq1YlTS1L9\nS6fTpNPpkpyrmNuORgMNRNs6wFSgCbiuzXGHA7/NHrciz3ky48dnmDOnawWVpO6oR9wd2qVbRItp\nonkWGAYMAfoAk4lO1lyDiXD/b+QPd8AmGklKUjFNNFuBy4DZxIiaGcQIminZ/dOB/w7sDtyYfW8L\n0TnbigEvSclJcmaYzHnnZbjzzgQ/UZJqXLmbaErGGrwkJSfx2SQlScmwBi9JdcqAl6Q6ZcBLUp2y\nDV6S6pQ1eEmqUwa8JNUpA16S6pQBL0l1yk5WSapT1uAlqU4Z8JJUpwx4SapTtsFLUp2yBi9JdarY\ngJ8ALAWWA1fm2X8w8DSwCbiivZMY8JKUnGKW7OsJTAPGA+uABcSarEtyjnkbuBw4o6MTGfCSlJxi\navCjiIW0VxNrrc4EJrU55k1ice4tHZ3IgJek5BQT8PsCa3Jer82+12l2skpScopposmU6sN+9rMG\ndtklnqdSKVKpVKlOLUl1IZ1Ok06nS3KuYlbqHg00EB2tAFOBJuC6PMf+C/A+8OM8+zIbNmTYffcu\nlFKSuqkePXpAcVm9jWKaaJ4FhgFDgD7AZKKTNW9ZOjqRbfCSlJxifytMBK4nRtTMAP4dmJLdNx0Y\nQIyu6UfU7t8DRhC1+WaZLVsy9CqmUUiSBGxfDb5LP9RFmUymZM35ktQtlLuJRpJUgwx4SapTBrwk\n1SkDXpLqlAEvSXXKgJekOmXAS1KdMuAlqU4Z8JJUpwx4SapTBrwk1SkDXpLqlAEvSXXKgJekOmXA\nS1KdKibgJwBLgeXAle0c89Ps/oXAyNIUTZK0PQoFfE9gGhHyI4DzgOFtjjkVOJBY1u9i4MYSl1F5\nlGpRXnktS83rWT0KBfwoYAWwGtgCzAQmtTnmdODX2efzgN2A/qUrovLxf6LS8VqWltezehQK+H2B\nNTmv12bfK3TMwO0vmiRpexQK+GIXUW27XqCLr0pShRVayHU00EC0wQNMBZqA63KO+QWQJppvIDpk\nTwDWtznXCmBo14sqSd3SK0Q/Z8n1yp58CNAHeJH8nawPZZ+PBp4pR0EkSaU3EVhG1MCnZt+bkt2a\nTcvuXwgclWjpJEmSJJVWMTdKqWOrgZeAF4D52ff2AOYA/w94hBieqvz+D9En9Kec9zq6flOJ7+tS\n4AsJlbFW5LuWDcTouRey28ScfV7Ljg0CHgMWAS8D/5B9vya+nz2JppshQG/yt+GrsFXEf/Bc/wP4\nbvb5lcAPEy1RbRlH3GGdG0rtXb8RxPe0N/G9XYFTeuTKdy3/BfhOnmO9loUNAI7MPt+FaA4fTo18\nP48DHs55/U/ZTZ2zCvh0m/eW0nJD2YDsa7VvCK1Dqb3rN5XWf2k+TAweUIshbBvwV+Q5zmvZefcD\n4ynR97PcyV/MjVIqLAM8CjwLfD37Xn9ahqKux7uHO6u967cP8T1t5ne2OJcTgyxm0NKc4LXsnCHE\nX0fzKNH3s9wB7w1PpTGW+A8/EfgG8Wdyrgxe6+1R6Pp5bTt2I7A/0dTQCPy4g2O9lvntAtwLfBN4\nr82+Ln8/yx3w64hOhGaDaP3bR8VpzD6+CdxHzBG0nvjTDWBv4I0KlKuWtXf92n5nB2bfU/veoCWE\nbiK+n+C1LFZvItxvI5pooETfz3IH/LPELJNDiBulJgMPlvkz681OQN/s852JXvM/Edfxa9n3v0bL\nF0PFae/6PQicS3xf9ye+v/O3+Wnl2jvn+Zm0tM97LQvrQTRrLQauz3m/Zr6f+W6UUvH2J3rNXySG\nUTVfwz2IdnmHSRb2H8BrwGaiT+hCOr5+VxHf16XAFxMtafVrey0vAm4lhvEuJIIotz/Ia9mx44np\nX16kZZjpBPx+SpIkSZIkSZIkSZIkSZIkSZIkSaoX/x8mAKT2WSiwSwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fc426b28bd0>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "modelOptimizer= ModelOptimizer(sk_transf, Y)\n",
      "modelOptimizer.add_model(\"Logistic\",LogisticRegression(),param_grid={'C':np.linspace(0.0001, 0.2, 10)})\n",
      "modelOptimizer.add_model(\"RandomForest\",RandomForestClassifier(),param_grid={'max_depth':range(5,9,1),'n_estimators':[90,200,300], 'max_features' : ['sqrt', 'log2'] } )\n",
      "modelOptimizer.test_models()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic: \n",
        "------------------------\n",
        "score: 0.706454594861\n",
        "best estomator:  LogisticRegression(C=0.022311111111111111, class_weight=None, dual=False,\n",
        "          fit_intercept=True, intercept_scaling=1, penalty='l2',\n",
        "          random_state=None, tol=0.0001)\n",
        "best params:  {'C': 0.022311111111111111}\n",
        "\n",
        "RandomForest: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "------------------------\n",
        "score: 0.686392906132\n",
        "best estomator:  RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=8, max_features='sqrt',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=300, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)\n",
        "best params:  {'max_features': 'sqrt', 'n_estimators': 300, 'max_depth': 8}\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "6. Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* We learned that the best models for this data set are random forest, AdaBoost and logistic regression. \n",
      "* Tweaking the different models showed some improvement, although not very significant. Feature selection is more important! \n",
      "* In this example, we use a pretty small data set. Using a larger Data set will \n",
      "  very likely improve our results. \n",
      "* We can use PCA to reduce the features dimension. \n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Future Work"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Working with larger data sets - use sparse matrix libraries and chunk data loading when the data is too big to \n",
      "  fit in memory\n",
      "* Working with <b> VERY </b> large data sets - use Java Mahout to run model on a distributed system. \n",
      "* Practical uses - test performance, we have very strict performance requirments in the bidder, model must be able to run on a  \n",
      "  single line in less than 20ms. \n",
      "* Try to give weights to features rather than users."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "7. Implementaion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def testDataFrame(df):   \n",
      "    X = df.drop(['Visited Brand'], axis=1)\n",
      "    Y = df['Visited Brand']\n",
      "    modelOptimizer= ModelOptimizer(X, Y)\n",
      "    modelOptimizer.add_model(\"Logistic\",LogisticRegression(),param_grid={'C':np.linspace(0.1, 0.4, 14)} )\n",
      "    modelOptimizer.add_model(\"RandomForest\",RandomForestClassifier(),param_grid={'max_depth':range(4,8,1)} )\n",
      "    modelOptimizer.test_models()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ModelOptimizer:\n",
      "    def __init__(self, x, y):\n",
      "        self.models = []\n",
      "    \n",
      "        (x_train, x_test,\n",
      "         y_train, y_test) = cv.train_test_split(x, y,\n",
      "                                        test_size=.2)\n",
      "        self.x_train = x_train\n",
      "        self.x_test = x_test\n",
      "        self.y_train = y_train\n",
      "        self.y_test = y_test\n",
      "        \n",
      "        \n",
      "    def add_model(self, name, model, param_grid={}):\n",
      "        optimized_model = gs.GridSearchCV(model, param_grid, scoring='roc_auc', n_jobs=4, cv=3) \n",
      "        optimized_model.fit(self.x_train, self.y_train)\n",
      "        data = {\n",
      "            'name':name,           \n",
      "            'model': optimized_model\n",
      "        }\n",
      "        self.models.append(data)\n",
      "        \n",
      "    def test_models(self):\n",
      "        for model in self.models:            \n",
      "            prob_array = np.array( model['model'].predict_proba(self.x_test))\n",
      "            y_hat = prob_array[:,1]\n",
      "            score = roc_auc_score(self.y_test, y_hat)     \n",
      "            #score = model['model'].score(self.x_test, self.y_test)\n",
      "            print \"%s: \" % model['name'] \n",
      "            print \"------------------------\"\n",
      "            print \"score: %s\" % (score)\n",
      "            print \"best estomator: \" ,model['model'].best_estimator_\n",
      "            print \"best params: \" , model['model'].best_params_\n",
      "            print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "def display_roc_curve(ytest, y_prob):\n",
      "    false_pos_rate, true_pos_rate, thresholds = roc_curve(ytest, y_prob[:, 1])\n",
      "    roc_auc = auc(false_pos_rate, true_pos_rate)\n",
      "    # Plot ROC curve\n",
      "    # setup figure\n",
      "    plt.figure(figsize=(5, 4))\n",
      "    plt.clf()\n",
      "    plt.plot(false_pos_rate, true_pos_rate, label='ROC curve (area = %0.2f)' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate')\n",
      "    plt.ylabel('True Positive Rate')\n",
      "    plt.title('Receiver operating characteristic')\n",
      "    plt.legend(loc=\"lower right\")\n",
      "    plt.show()\n",
      "\n",
      "def printPredictionPlot(Y_test_predicted_prob, Y_test):\n",
      "    prob_df = pd.DataFrame(Y_test_predicted_prob[:10], columns=['0 predicted prob', '1 predicted prob'])\n",
      "    prob_df ['actual value'] = Y_test[:10]\n",
      "    pd.options.display.float_format = '{:10,.3f}'.format\n",
      "    \n",
      "    tmp = plt.hist(Y_test_predicted_prob[:,1],20)\n",
      "    plt.xlabel('Probability for 1')\n",
      "    plt.ylabel('Number of users with probability')\n",
      "    print tmp\n",
      "    \n",
      "def printConfusionMatrix(model, threshold, X_train, X_test, Y_train, Y_test):\n",
      "    \n",
      "    model.fit(X_train,Y_train) \n",
      "    y_pred = predictWithThreshhold(model, threshold, X_test)\n",
      "    \n",
      "    print metrics.confusion_matrix(Y_test, y_pred)   \n",
      "    \n",
      "def predictWithThreshhold(model, threshhold, x_test):\n",
      "    \n",
      "    prob = model.predict_proba(x_test)\n",
      "    return map(lambda x: 1 if x[1] > threshhold else 0, prob)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}